{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Text Classification\n",
    "\n",
    "In this notebook we want to explore how to do text classification. This involves some fundamental text preprocessing steps that are common for NLP (natural language processing) tasks. We will work with the IMDB dataset, which is luckily [part of the Keras datasets library](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb).\n",
    "\n",
    "This dataset consists of 50.000 movie reviews and our goal is to classify whether the review is positive or negative. We will work through the problem step by step and see more explanations along the way. Let's first import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained before we are using `keras` and with that come [some wonderful datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets). We first select the dataset and then download the data and split it into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = keras.datasets.imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is noteworthy is the `num_words=10000` property. This limits the data to only contain the 10.000 most frequently occurring words. While it may seem like we are losing some amount of information by this (which is absolutely true) it is simply done for computation purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at the data\n",
    "\n",
    "Now that we have the training and testing data at our fingertips we will have a look at it. First of all let's check the size of the respective sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 25000, Test set size: 25000\n",
      "Training labels mean: 0.5, test labels mean: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set size: {}, Test set size: {}\".format(len(train_data), len(test_data)))\n",
    "print(\"Training labels mean: {}, test labels mean: {}\".format(train_labels.mean(), test_labels.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that all the data (50.000 reviews) is not only evenly split but each set also has an even distribution of positive and negative reviews.\n",
    "\n",
    "So let's take a look at how much words a review might have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218 189 141 550 147 "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(len(train_data[i]), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we already see that our reviews are of various length. This makes it difficult to work with as normal systems need an input of constant size. We have a pretty simple way to deal with it but let's first take a look at a real review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 14 22 16 43 530 973 1622 1385 65 458 4468 66 3941 4 173 36 256 5 25 100 43 838 112 50 670 2 9 35 480 284 5 150 4 172 112 167 2 336 385 39 4 172 4536 1111 17 546 38 13 447 4 192 50 16 6 147 2025 19 14 22 4 1920 4613 469 4 22 71 87 12 16 43 530 38 76 15 13 1247 4 22 17 515 17 12 16 626 18 2 5 62 386 12 8 316 8 106 5 4 2223 5244 16 480 66 3785 33 4 130 12 16 38 619 5 25 124 51 36 135 48 25 1415 33 6 22 12 215 28 77 52 5 14 407 16 82 2 8 4 107 117 5952 15 256 4 2 7 3766 5 723 36 71 43 530 476 26 400 317 46 7 4 2 1029 13 104 88 4 381 15 297 98 32 2071 56 26 141 6 194 7486 18 4 226 22 21 134 476 26 480 5 144 30 5535 18 51 36 28 224 92 25 104 4 226 65 16 38 1334 88 12 16 283 5 16 4472 113 103 32 15 16 5345 19 178 32'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([str(train_data[0][x]) for x in range(len(train_data[0]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well if that isn't a positive review I don't know what is!? As we see these values are encoded. Each of these integers is standing for a word but because it is easier to work with integers than with strings the words are encoded. \n",
    "\n",
    "Fortunately we can get a dictionary of the mappings from words to integers so we can use those to translate our review into a more human readable form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "\n",
    "word_index[\"and\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it works that we can find the encoding for a certain word but of course we want to also be able to decode the integers into the real word strings. We write a little helper function for this. \n",
    "\n",
    "But first we need to reserve some integer encodings for some basic things and therefore increase all the other integer encodings. Especially we need the following:\n",
    "\n",
    "* `<PAD>`: As mentioned before we need to find a way to make our input one similar length. We will use padding for this which will become more clear in just a bit\n",
    "* `<START>`: Pretty self-explanatory but we need an indication where our review starts\n",
    "* `<UNK>`: This will represent the *unknown* encoding. Remember that we limited our vocabulary size to only the 10.000 most frequent words. All other words will get this encoding.\n",
    "* `<UNUSED>`: also self-explanatory, used for unused words\n",
    "\n",
    "So let's create all of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {k: (v+3) for k, v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "\n",
    "reverse_word_index = dict([(v, k) for (k, v) in word_index.items()])\n",
    "\n",
    "def decode_review(review):\n",
    "    return \" \".join([reverse_word_index.get(x, \"?\") for x in review])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally try to read the whole movie review which was cryptic before (Spoiler alert: it really is positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "\n",
    "In order to start building up and eventually training our model we need to do some preprocessing. First off we need a uniform input length for our network. One way would be to create a sort of \"one-hot-encoding\" where one means \"all-words-appearing-in-the-review\". This might sound intuitive first but will create a massive matrix of the size `num_words * num_reviews`.\n",
    "\n",
    "We can use a simpler approach and simple select a certain size and add padding to reviews that are smaller and cut off longer reviews. We will lose some information but hopefully can classify from the amount of words already analyzed. But how do we do that?\n",
    "\n",
    "I'm glad you asked! Again `keras` comes to the rescue as it offers a `preprocessing.sequence.pad_sequences` method to do all this work for us. So let's use it for our `train_data` and `test_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding=\"post\",\n",
    "                                                       maxlen=256)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                      value=word_index[\"<PAD>\"],\n",
    "                                                      padding=\"post\",\n",
    "                                                      maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 256 256 256 256 "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(len(train_data[i]), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that now all reviews are of the same length. With this we can start building our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "We will use a plain neural network here which is the `keras.Sequential()` model but it has some special layers included. Let's first think of what we need to go through here:\n",
    "\n",
    "1. Make use of the encodings and the word information we have\n",
    "2. Use hidden units to learn how to predict from the data\n",
    "3. Get a prediction of 0 (\"negative\") or 1 (\"positive\") in the end (which will be represented by a probability)\n",
    "\n",
    "We can tackle this with the following model and take a look at each layer in a second:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Stefan\\Anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Embedding(vocab_size, 16))\n",
    "model.add(layers.GlobalAveragePooling1D())\n",
    "model.add(layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's go through the layers one-by-one:\n",
    "\n",
    "* `Embedding`: The way we represent our words are in a multi-dimensional space. The idea here is the same as in the [word2vec](https://en.wikipedia.org/wiki/Word2vec) concept where each word is a vector in that space (in this case 16 dimensional). If we have this representation we can cluster similar words closer to each other and then infer some meaning by their (Euclidean) distances.\n",
    "\n",
    "* `GlobalAveragePooling1D`: The idea of a pooling layer is rather simple: in order to reduce the dimensionality we can combine multiple values and take their average (if we look at convolutions taking the maximum is more common).\n",
    "\n",
    "* `Dense`: This a just a standard fully-connected layer. The first one has 16 hidden units and the `tf.nn.relu` activation function which is the standard for fully-connected layers. The second one only 1 hidden unit and uses a `tf.nn.sigmoid` activation. In case you were wondering why that is, the `tf.nn.sigmoid` function maps a value into the range of 0 and 1. We use this because our desired output is a probability p whether or not our review was positive (or probability 1-p to indicate whether it was negative).\n",
    "\n",
    "(Note: The `model.summary()` command gives us a great overview of our model and the different layers. Also the indication of the amount of trainable parameters can be really helpful to get a feel about the size of our model.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function and optimizer\n",
    "\n",
    "In order to train our model we need to first `compile` it. Here it is necessary to specify 3 more properties:\n",
    "\n",
    "* `optimizer`: Our model learns by adjusting the parameters that are contained inside our different layers. The `optimizer` specifies in which direction and by how much we need to adjust these parameters and is therefore one key element as it is key in the learning phase of our network. The `adam` optimizer is also one of the standard optimizers used in neural network training.\n",
    "\n",
    "* `loss`: After we predict an output in our training phase we want our model to get better. This is why we need to calculate a `loss` which can be understood as: How far was our prediction off? This is crucial so that we can then use the optimizer to adjust our parameters. As we have a single probability output we choose the `binary_crossentropy` but this is highly dependent on the use-case.\n",
    "\n",
    "* `metrics`: We want to know how well we are predicting. In this case it is really simple as we can either be right or wrong with our prediction. This is why we choose the `accuracy` metric to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "             loss=\"binary_crossentropy\",\n",
    "             metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation set\n",
    "\n",
    "In neural network training we have a high risk of **overfitting**. This means that the network might learn certain properties of the training set that are not applicable to the general problem. The reason for this is that the network has so many parameters that it has the capacity to do so. \n",
    "\n",
    "There are several techniques to detect and prevent this problem. One that is used here is to create a **validation set**. We take portion of the data away from our **training set** and keep it hidden from the network during the training phase. Therefore it won't be able to overly adjust to these samples. After we trained the network we evaluate on this validation set. This gives a better indication on the performance of our algorithm as its properties could not have been learnt by heart by the network.\n",
    "\n",
    "(Note: it is important to split the data in a way that both datasets are still representative of the problem. Otherwise it will lead to a whole lot of different problems.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = train_data[:10000]\n",
    "partial_x_train = train_data[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "partial_y_train = train_labels[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "Now we are all set to finally start training our model with the `model.fit()` function. However there is still some more parameters to set and tweak:\n",
    "\n",
    "* `epochs`: An epoch is one run through our training procedure where the network sees the whole data. You might say it is enough to see all data once but it is common practice to make multiple runs (in some cases even thousands) depending on the size of your dataset. This will increase the performance of our network but we need to be careful to not be overfitting.\n",
    "\n",
    "* `batch_size`: We use so called *mini-batches* of size 512 to send throught the network at a time. This speeds up the training procedure.\n",
    "\n",
    "* `validation_data`: As mentioned before the validation data is used to get a sense of how well our network is performing on unseen data.\n",
    "\n",
    "* `verbose`: This is just a `Tensorflow` property to increase the output we see during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From C:\\Users\\Stefan\\Anaconda3\\envs\\tf-env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 1s 44us/sample - loss: 0.6919 - acc: 0.5099 - val_loss: 0.6898 - val_acc: 0.5391\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 0s 12us/sample - loss: 0.6867 - acc: 0.5604 - val_loss: 0.6826 - val_acc: 0.6153\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 0s 13us/sample - loss: 0.6758 - acc: 0.6163 - val_loss: 0.6689 - val_acc: 0.6350\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 0s 12us/sample - loss: 0.6579 - acc: 0.6651 - val_loss: 0.6488 - val_acc: 0.6594\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.6335 - acc: 0.6975 - val_loss: 0.6237 - val_acc: 0.7102\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.6046 - acc: 0.7344 - val_loss: 0.5958 - val_acc: 0.7416\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 0s 12us/sample - loss: 0.5737 - acc: 0.7691 - val_loss: 0.5677 - val_acc: 0.7686\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 0s 12us/sample - loss: 0.5434 - acc: 0.8043 - val_loss: 0.5415 - val_acc: 0.7881\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.5151 - acc: 0.8249 - val_loss: 0.5179 - val_acc: 0.8059\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.4893 - acc: 0.8449 - val_loss: 0.4975 - val_acc: 0.8141\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.4663 - acc: 0.8618 - val_loss: 0.4801 - val_acc: 0.8297\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.4456 - acc: 0.8736 - val_loss: 0.4637 - val_acc: 0.8495\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 0s 12us/sample - loss: 0.4273 - acc: 0.8833 - val_loss: 0.4492 - val_acc: 0.8575\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.4100 - acc: 0.8937 - val_loss: 0.4384 - val_acc: 0.8507\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.3944 - acc: 0.9001 - val_loss: 0.4289 - val_acc: 0.8528\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.3800 - acc: 0.9069 - val_loss: 0.4185 - val_acc: 0.8654\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.3660 - acc: 0.9109 - val_loss: 0.4104 - val_acc: 0.8605\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.3532 - acc: 0.9173 - val_loss: 0.4047 - val_acc: 0.8637\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.3413 - acc: 0.9215 - val_loss: 0.3960 - val_acc: 0.8676\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 0s 12us/sample - loss: 0.3302 - acc: 0.9255 - val_loss: 0.3885 - val_acc: 0.8735\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.3185 - acc: 0.9307 - val_loss: 0.3833 - val_acc: 0.8750\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.3083 - acc: 0.9351 - val_loss: 0.3800 - val_acc: 0.8741\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.2981 - acc: 0.9400 - val_loss: 0.3787 - val_acc: 0.8667\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 0s 12us/sample - loss: 0.2891 - acc: 0.9430 - val_loss: 0.3695 - val_acc: 0.8772\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 0s 12us/sample - loss: 0.2798 - acc: 0.9457 - val_loss: 0.3680 - val_acc: 0.8779\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 0s 12us/sample - loss: 0.2709 - acc: 0.9501 - val_loss: 0.3660 - val_acc: 0.8748\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.2628 - acc: 0.9530 - val_loss: 0.3628 - val_acc: 0.8761\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.2551 - acc: 0.9563 - val_loss: 0.3613 - val_acc: 0.8741\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.2475 - acc: 0.9575 - val_loss: 0.3598 - val_acc: 0.8760\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 0s 10us/sample - loss: 0.2399 - acc: 0.9612 - val_loss: 0.3578 - val_acc: 0.8779\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.2326 - acc: 0.9636 - val_loss: 0.3529 - val_acc: 0.8799\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.2259 - acc: 0.9657 - val_loss: 0.3556 - val_acc: 0.8792\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.2194 - acc: 0.9666 - val_loss: 0.3558 - val_acc: 0.8774\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.2134 - acc: 0.9680 - val_loss: 0.3506 - val_acc: 0.8787\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.2072 - acc: 0.9705 - val_loss: 0.3569 - val_acc: 0.8767\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 0s 10us/sample - loss: 0.2017 - acc: 0.9711 - val_loss: 0.3527 - val_acc: 0.8785\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.1958 - acc: 0.9730 - val_loss: 0.3507 - val_acc: 0.8787\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.1907 - acc: 0.9735 - val_loss: 0.3527 - val_acc: 0.8762\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 0s 10us/sample - loss: 0.1856 - acc: 0.9747 - val_loss: 0.3584 - val_acc: 0.8747\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 0s 11us/sample - loss: 0.1803 - acc: 0.9763 - val_loss: 0.3514 - val_acc: 0.8775\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=40,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val, y_val),\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Of course we need to evaluate our model and therefore we use the **test set**. This is needed because this data is something the network has never seen and (in the case it is representative of our problem space) gives an intuition how well the model will generalize.\n",
    "\n",
    "(Note: if you are confused by the difference between *validation* and *test* set here is an explanation: the validation set is used during the training phase to evaluate the performance after each *epoch*. It is therefore data that the network has seen before and if we will optimize for accuracy on that we might be overfitting to the validation set. The *test* set is something the algorithm has never seen before and by that a good way for a final evaluation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 32us/sample - loss: 0.3696 - acc: 0.8680\n",
      "[0.36963458097457885, 0.86796]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with this simple model we already get a pretty good accuracy of around `87 %`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closer look at the history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's take a closer look at the development of the training and the validation loss and accuracy over time. This gives a solid indication if we were overfitting to our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4VPXZ//H3DaKsCgJ1AUlwV0LAmOKGu1W01r0/odiKVmhVWh+tj7WFqrVan2qt1qWt1NqqxCpdUFwqrUpFbW3FDcUFEQEjCGFTNpGQ+/fH90wySWYyk2Uyk5nP67rONXOWOXPPCZz7nO92zN0REREB6JTtAEREJHcoKYiISC0lBRERqaWkICIitZQURESklpKCiIjUUlKQRsyss5mtN7NBbbltNpnZnmbW5u2vzew4M1sUN/+umR2ezrYt+K67zeyHLf28SDq2yXYA0npmtj5utjuwGdgazX/L3Suasz933wr0bOttC4G779MW+zGzC4Bz3P2ouH1f0Bb7FmmKkkIecPfak3J0JXqBuz+VbHsz28bdq9sjNpFU9O8xt6j4qACY2XVm9pCZ/dHM1gHnmNkhZvaima01s2VmdpuZdYm238bM3MyKo/mp0fq/mdk6M/u3mQ1u7rbR+hPNbL6ZfWJmt5vZC2Y2Lknc6cT4LTNbYGZrzOy2uM92NrNbzGyVmb0PjGri+Ew2swcbLLvTzH4Rvb/AzN6Ofs/70VV8sn1VmtlR0fvuZnZ/FNs84MAE37sw2u88MzslWj4UuAM4PCqaWxl3bK+J+/y3o9++ysweNrNd0jk2zTnOsXjM7CkzW21mH5vZFXHf86PomHxqZnPMbNdERXVm9nzs7xwdz9nR96wGJpvZXmY2K/otK6PjtkPc54ui31gVrf+lmXWNYt4vbrtdzGyjmfVN9nslBXfXlEcTsAg4rsGy64DPga8QLgS6AV8EDiLcLe4OzAcmRttvAzhQHM1PBVYC5UAX4CFgagu2/QKwDjg1WncZsAUYl+S3pBPjI8AOQDGwOvbbgYnAPGAg0BeYHf65J/ye3YH1QI+4fa8AyqP5r0TbGHAMsAkojdYdByyK21clcFT0/ufAP4E+QBHwVoNt/x+wS/Q3+VoUw07RuguAfzaIcypwTfT++CjG4UBX4FfAM+kcm2Ye5x2A5cAlwHbA9sCIaN0PgNeBvaLfMBzYEdiz4bEGno/9naPfVg1cCHQm/HvcGzgW2Db6d/IC8PO43/NmdDx7RNsfFq2bAlwf9z3fA6Zn+/9hR56yHoCmNv6DJk8Kz6T43OXAn6L3iU70v4nb9hTgzRZsez7wXNw6A5aRJCmkGePBcev/ClwevZ9NKEaLrTup4Ymqwb5fBL4WvT8RmN/Eto8BF0fvm0oKS+L/FsBF8dsm2O+bwJej96mSwr3AT+PWbU+oRxqY6tg08zh/HZiTZLv3Y/E2WJ5OUliYIoazgJei94cDHwOdE2x3GPABYNH8a8AZbf3/qpAmFR8Vjg/jZ8xsXzN7PCoO+BS4FujXxOc/jnu/kaYrl5Ntu2t8HB7+F1cm20maMab1XcDiJuIFeAAYE73/GlBbOW9mJ5vZf6Lik7WEq/SmjlXMLk3FYGbjzOz1qAhkLbBvmvuF8Ptq9+funwJrgAFx26T1N0txnHcDFiSJYTdCYmiJhv8edzazaWb2URTDHxrEsMhDo4Z63P0Fwl3HSDMrAQYBj7cwJkF1CoWkYXPMuwhXpnu6+/bAVYQr90xaRriSBcDMjPonsYZaE+MywskkJlWT2YeA48xsIKF464Eoxm7An4EbCEU7vYG/pxnHx8liMLPdgV8TilD6Rvt9J26/qZrPLiUUScX214tQTPVRGnE11NRx/hDYI8nnkq3bEMXUPW7Zzg22afj7fkZoNTc0imFcgxiKzKxzkjjuA84h3NVMc/fNSbaTNCgpFK5ewCfAhqii7lvt8J2PAWVm9hUz24ZQTt0/QzFOA/7HzAZElY7fb2pjd19OKOL4PfCuu78XrdqOUM5dBWw1s5MJZd/pxvBDM+ttoR/HxLh1PQknxipCfryAcKcQsxwYGF/h28AfgW+aWamZbUdIWs+5e9I7ryY0dZxnAIPMbKKZbWtm25vZiGjd3cB1ZraHBcPNbEdCMvyY0KChs5lNIC6BNRHDBuATM9uNUIQV829gFfBTC5X33czssLj19xOKm75GSBDSCkoKhet7wLmEit+7CFfKGRWdeM8GfkH4T74H8CrhCrGtY/w18DTwBvAS4Wo/lQcIdQQPxMW8FrgUmE6orD2LkNzScTXhjmUR8DfiTljuPhe4DfhvtM2+wH/iPvsP4D1guZnFFwPFPv8koZhnevT5QcDYNONqKOlxdvdPgC8BZxIqtucDR0arbwIeJhznTwmVvl2jYsHxwA8JjQ72bPDbErkaGEFITjOAv8TFUA2cDOxHuGtYQvg7xNYvIvydP3f3fzXzt0sDscoZkXYXFQcsBc5y9+eyHY90XGZ2H6Hy+ppsx9LRqfOatCszG0UoDviM0KSxmnC1LNIiUf3MqcDQbMeSDzJWfGRm95jZCjN7M8l6izqvLDCzuWZWlqlYJKeMBBYSihVGAaepYlBaysxuIPSV+Km7L8l2PPkgY8VHZnYEoTPOfe5ekmD9ScB3CO3HDwJ+6e4HZSQYERFJS8buFNx9NqFiLplTCQnD3f1FoLdF3fRFRCQ7slmnMID6HVgqo2XLGm4YNWmbANCjR48D991334abiIhIE15++eWV7t5UE3Agu0khUeefhGVZ7j6F0NyN8vJynzNnTibjEhHJO2aWqlc/kN1+CpXU7+05kNA8UUREsiSbSWEG8I2oFdLBwCfu3qjoSERE2k/Gio/M7I/AUUA/M6sk9FjsAuDuvwGeILQ8WkAYrOu8TMUiIiLpyVhScPcxKdY7cHFbfNeWLVuorKzks88+a4vdSYZ07dqVgQMH0qVLsuF8RCTb8qJHc2VlJb169aK4uJgw8KbkGndn1apVVFZWMnjw4NQfEJGsyIsB8T777DP69u2rhJDDzIy+ffvqbk6kBSoqoLgYOnUKrxUVqT7RcnmRFAAlhA5AfyMpVKlO6k2tr6iACRNg8WJwD68TJmQuMeRNUhARyZRMntRTrZ80CTZurP99GzeG5RmR7eeBNnc68MADvaG33nqr0bL2tHLlSh82bJgPGzbMd9ppJ991111r5zdv3pzWPsaNG+fvvPNOk9vccccdPnXq1LYIOWuy/bcSSWbqVPeiInez8Br7rzZ1qnv37u7hlB2m7t3TX19UVH9dbCoqSm+9WeL1Zs37fSR51nbDKesn+eZObZEUkv3x28LVV1/tN910U6PlNTU1vnXr1rb7og5KSUEyJdX/66bWN3Viz/RJPdX6VPtPV7pJoeCKj9qzfG7BggWUlJTw7W9/m7KyMpYtW8aECRMoLy9nyJAhXHvttbXbjhw5ktdee43q6mp69+7NlVdeybBhwzjkkENYsWIFAJMnT+bWW2+t3f7KK69kxIgR7LPPPvzrX+GBUxs2bODMM89k2LBhjBkzhvLycl577bVGsV199dV88YtfrI0v/JuB+fPnc8wxxzBs2DDKyspYtGgRAD/96U8ZOnQow4YNY1LG7ltFkstWEc2SJANyx5anWj8oydPBY8tTrb/+eujevf667t3D8oxIJ3Pk0tTaO4W2yrrJxN8pvPfee25m/t///rd2/apVq9zdfcuWLT5y5EifN2+eu7sfdthh/uqrr/qWLVsc8CeeeMLd3S+99FK/4YYb3N190qRJfsstt9Ruf8UVV7i7+yOPPOInnHCCu7vfcMMNftFFF7m7+2uvveadOnXyV199tVGcsThqamp89OjRtd9XVlbmM2bMcHf3TZs2+YYNG3zGjBk+cuRI37hxY73PtoTuFCSZll7Ju2f2ar61+25t8VOqY5MudKeQWKqs3tb22GMPvvjFL9bO//GPf6SsrIyysjLefvtt3nrrrUaf6datGyeeeCIABx54YO3VekNnnHFGo22ef/55Ro8eDcCwYcMYMmRIws8+/fTTjBgxgmHDhvHss88yb9481qxZw8qVK/nKV74ChM5m3bt356mnnuL888+nW7duAOy4447NPxAiJL/ab21layav5lNdqadaP3YsTJkCRUVgFl6nTAnL01kf22bRIqipCa9jW/o07jQUXFJIdavW1nr06FH7/r333uOXv/wlzzzzDHPnzmXUqFEJ2+1vu+22te87d+5MdXV1wn1vt912jbZxT/3QpI0bNzJx4kSmT5/O3LlzOf/882vjSNRs1N3VnFTS0tIintae9DNZRNMeJ/X2POmnUnBJod3L5+J8+umn9OrVi+23355ly5Yxc+bMNv+OkSNHMm3aNADeeOONhHcimzZtolOnTvTr149169bxl7/8BYA+ffrQr18/Hn30USB0Cty4cSPHH388v/vd79i0aRMAq1c39ewkyWetKddvTbl9a8vd2+JqvqOc1Fur4JJCOlk9U8rKyth///0pKSlh/PjxHHbYYW3+Hd/5znf46KOPKC0t5eabb6akpIQddtih3jZ9+/bl3HPPpaSkhNNPP52DDqp7CmpFRQU333wzpaWljBw5kqqqKk4++WRGjRpFeXk5w4cP55ZbbmnzuCU3ZOqkD02f+Ft70u9oRTQ5LZ2Kh1yacrGfQi7ZsmWLb9q0yd3d58+f78XFxb5ly5YsR1VHf6vsymRlbmuaVrZXZWshQ/0UCtOaNWu8rKzMS0tLfejQoT5z5sxsh1SP/lbZk82Tfjrfr5N+ZikpSE7S3yrzkp1cs33Sbyo2ybx0k0LB1SmIdHQtLffPdGWuyu3zRDqZI5cm3Sl0bPpbtU5rioB0pV/Y0J2CSMfU1J1Aa1r46Epf0pEXT14TyRex4p/YiT9W/APhBJxOEdDixY3XDxpUdwKP9QuI9dZteNLXib6w6U6hDRx11FGNOqLdeuutXHTRRU1+rmfPngAsXbqUs846K+m+58yZ0+R+br31VjbGXT6edNJJrF27Np3QJQtacyfQFuX+utKXpigptIExY8bw4IMP1lv24IMPMmbMmLQ+v+uuu/LnP/+5xd/fMCk88cQT9O7du8X7k8xJ1QEs1Z1AWxQBiTRFSaENnHXWWTz22GNs3rwZgEWLFrF06VJGjhzJ+vXrOfbYYykrK2Po0KE88sgjjT6/aNEiSkpKgDAExejRoyktLeXss8+uHVoC4MILL6wddvvqq68G4LbbbmPp0qUcffTRHH300QAUFxezcuVKAH7xi19QUlJCSUlJ7bDbixYtYr/99mP8+PEMGTKE448/vt73xDz66KMcdNBBHHDAARx33HEsX74cgPXr13PeeecxdOhQSktLa4fJePLJJykrK2PYsGEce+yxbXJsO6JM3gmo3F8yLp3a6FyaUrU+uuQS9yOPbNvpkktS1+yfdNJJ/vDDD7t7GL768ssvd/fQw/iTTz5xd/eqqirfY489vKamxt3de/To4e7uH3zwgQ8ZMsTd3W+++WY/77zz3N399ddf986dO/tLL73k7nVDVldXV/uRRx7pr7/+uru7FxUVeVVVVW0ssfk5c+Z4SUmJr1+/3tetW+f777+/v/LKK/7BBx94586da4fU/upXv+r3339/o9+0evXq2lh/+9vf+mWXXebu7ldccYVfEndQVq9e7StWrPCBAwf6woUL68XaUL63PkrVgidVX4B0WgCJtARqfdS+4ouQ4ouO3J0f/vCHlJaWctxxx/HRRx/VXnEnMnv2bM455xwASktLKS0trV03bdo0ysrKOOCAA5g3b17Cwe7iPf/885x++un06NGDnj17csYZZ/Dcc88BMHjwYIYPHw4kH567srKSE044gaFDh3LTTTcxb948AJ566ikuvvji2u369OnDiy++yBFHHMHgwYOB/B9eO9ndQHvcCYhkUt61PopKSNrdaaedxmWXXcYrr7zCpk2bKCsrA8IAc1VVVbz88st06dKF4uLihMNlx0s0TPUHH3zAz3/+c1566SX69OnDuHHjUu4nXBwkFht2G8LQ24mKj77zne9w2WWXccopp/DPf/6Ta665pna/DWNMtKwjiw3nnKiVTlMthNKpE4j/LDQepVctgCSbdKfQRnr27MlRRx3F+eefX6+C+ZNPPuELX/gCXbp0YdasWSxO1F4wzhFHHEFFdNn55ptvMnfuXCAMu92jRw922GEHli9fzt/+9rfaz/Tq1Yt169Yl3NfDDz/Mxo0b2bBhA9OnT+fwww9P+zd98sknDBgwAIB77723dvnxxx/PHXfcUTu/Zs0aDjnkEJ599lk++OADoGMPr92a0UB1JyAdnZJCGxozZgyvv/567ZPPAMaOHcucOXMoLy+noqKCfffdt8l9XHjhhaxfv57S0lJuvPFGRowYAYSnqB1wwAEMGTKE888/v96w2xMmTODEE0+srWiOKSsrY9y4cYwYMYKDDjqICy64gAMOOCDt33PNNdfw1a9+lcMPP5x+/frVLp88eTJr1qyhpKSEYcOGMWvWLPr378+UKVM444wzGDZsGGeffXba35MN2eogBqoIlhyXTsVDLk0a5qJjy4W/VWsrg9MZLkJDQUiuQRXNIompg5hIckoKkpeaKh5SBzGR5PKm9ZHnWeuXfORNtIZqS6nGD2pqfKDYNqAxgqQw5cWdQteuXVm1alW7nXSk+dydVatW0bVr1zbZX2sqilUZLJJcXtwpDBw4kMrKSqqqqrIdijSha9euDBw4sNX7ae1IouncCYgUKsvk1bWZjQJ+CXQG7nb3/2uwvgi4B+gPrAbOcffKpvZZXl7uqUYNlfxWXJy4+KeoKFzVp1ovUojM7GV3L0+1XcaKj8ysM3AncCKwPzDGzPZvsNnPgfvcvRS4FrghU/FIx5OsiKi1FcUiklwmi49GAAvcfSGAmT0InArED9izP3Bp9H4W8HAG45EOpKkioraoKBaRxDJZ0TwA+DBuvjJaFu914Mzo/elALzPrm8GYJIe0tLJYFcUimZPJpJCofWjDCozLgSPN7FXgSOAjoLrRjswmmNkcM5ujyuT80JqHzaifgEjmZKyi2cwOAa5x9xOi+R8AuHvCegMz6wm84+5NNk9RRXN+UGWxSPvKekUz8BKwl5kNNrNtgdHAjPgNzKyfmcVi+AGhJZIUAFUWi+SmjCUFd68GJgIzgbeBae4+z8yuNbNTos2OAt41s/nAToD+yxcIDTEtkpsy2k8hE1R81HE050E1EO4EdOIXyYxcKD6SApaqIll3AiK5SXcKkhGqKBbJLeneKeTF2EeSe1JVJItUV8OyZVBZGaaPPgqvVVWw3XbQrVsoUuzevf777beHnXeGXXYJUzpjLLqHoso1a6BHD+jdO9yhNkdsH1u2wNatYaqpqXu/dWuIe+edQ9+bjkpJQVqsqTqDVL2OpeU+/xzuvRcWLgwnqU2bwmts2rQJNm8Od2tDhtRNe+wB26TxP949nOw6d25ZfO6wdi0sXRpO9PGvsfcffQQffxy+J163btC/fzjxxn7L5583/X29e9cliF12gS5dYPXqxlP8frp3hwEDYODA+tPOO8Onn4ZktXRpeI1NH38c4kmla1cYPDgc7913D6+x94MGhaSUji1b4P334d13wzR/PnzjG3DEEel9vqWUFKRFUo1Uev31iSuS861JaXU1rFwZpqqq+tO6deE39+wJvXqF1/j3RUWw667pf5c7zJgBl18OCxaEk1/s6rnhFXWvXvDf/8JDD9V9frvtYN99Q4IYPBjWr0988ly9Opysd9658UkzdiI1S3yyj71PdPLs0yd8ftddYejQxvscODBs0/AKvro67C+W/NauDSfo+BN27CT+wgvhZNq3L+y4Y/i9O+5YN9+7d/jdsbuSykp49tnw2eoG3WZ32KEu0RxySHjt3x+23TYkzNjUqVPd+02bQrJ+//0wzZoFGzbU328s8fXvD/361X+/enVdEli4MNx9xOy0Exx5ZPr/XlpKdQrSIunUGTR1J9FRbdoEf/87TJ8OTz4Jy5cn37ZHj7B9w6vhGDM44QT41rfg5JObvoqfOxcuvRSeeQb22w9+8QsYNSp1vBs2wNtvw7x5YXrzzfC6ZEkohtlxx8RTp07hRBk7cVZWhivoRLp1qzvZDxgQTp4DBjRe1q1b6nizpaYGVqwIyWWHHUJCbNhPpiXcwwVCLEl89FH9C4f4i4kNG8Jdxl57wT771J/23jsktNZIt05BSUFapFOn8A++IbPkJ8GO6tNP4fHH4a9/hb/9Lfzn7d0bvvxl2HPPuiu9+Klv33CSdw+JYf36cOcQ//rvf8PvfhdOFLvuCt/8JlxwQf0ithUr4Ec/grvvDt957bXhDqxLl9b9ppqa5pd7r1tXd4XtXnfS32GH5pfPS2ObNoW7uUzVRygpSEblc+ui6mp4661w0p4xA556KpRH77QTnH46nHEGHHVU60/Mse964gm4666QcABOPDGc+OfPh+uuC0UmEyfCVVeF4hWRlkg3KeDuHWo68MADXdrH1KnuRUXuZuF16tT667p3dw/XjGHq3r3+Npn2wQfut9/u/q9/uW/Z0rJ91NS4L1rkPm2a++WXux9+eP3fVVzsftll7s8/715d3abhN7Jokfvkye677FL3/Sef7P7OO5n9XikMwBxP4xyrOwVJKJ0ex9mqM3APxS6XXhqKYSCUjx99NBx3XJj22adxkcZnn8E774Ry9TfeCNMrr9TVC2y3HRxwAIwYUTftuWf7F41s2QIzZ4bflOmWJlI4VHwkrZKrxUPLlsH48aGM/+ij4ZZbQjHLU0+FaeHCsN2AASE5FBfXVbC+915da44uXUKF7fDhcNBBIQGUloaWJSL5SElBWqWtKpI3bAj7aouWJw89BBddFO5efvazUM7esFJu4UJ4+mn4xz/C65o1oX340KFQUlL3utdebVMnINJRqEeztEprO5+99Rbcdhvcd184cZ91Fpx7bmhn3dzWFatWwcUXh6QwYkTouLXvvom33X33MI0fH5LX5s253RRSJNd04M7YkkkteZ5BTU1oSXPCCaGD1B/+AGPGhGn6dDjmmNBpavLkUOSTyvr18Mgj4cr+L3+Bn/wkdE5KlhAaaqs7FJFCouIjSSrdiuT160MCuP32cLLfdddQzDNhQmizD6EN9iOPhKv8v/89JJCDD4avfz1UqC5ZAh9+WDctWRJ6rkJICvfdFyqBRaRlVKcgaWltC6IpU+CKK+CTT0KF7SWXwJlnNl1hu3QpPPBASBBvvlm3vG9f2G23+tPgwXDaaaFlkIi0nJKCpNTaB93cd1+oJzj22NDJ6uCDm/f97mGMl06dwrg3bTGsgIgkpqQgKbWm2ekjj4Q7gqOOCs1DdSUvktv05DVJqaXPPJg1C84+G8rL4eGHlRBE8omSQgFL1ry0qWanc+bAKaeEnr6PPx6GgBaR/KGkUMCa2+z07bfDcM39+oUWRH37Zj5GEWlfSgoFbOzYUKlcVBR6KhcVJa9kXrQIvvSl0Av4qaea93AYEek41KO5wI0dm7ql0fLlISFs2BCeUrXHHu0Tm4i0P90p5LmKitDKqFOn8FpR0bzPr1kTeigvXRrqEEpLMxGliOQK3SnksVTPUU5l4cLwmMgFC+DRR+HQQzMXq4jkBt0p5LFJk+p3TIMwP2lS6s++8ELoobx8eRhx9IQTMhOjiOQWJYU81tJ+CFOnhsHr+vSBF18MI5uKSGFQUshjze2HUFMTHhL/9a+HoqIXXwzPHRCRwqGkkMea0w9h06YwxPV118H554fHQe64Y/vEKSK5Q0khj6XbD2H58vBoyz/9KTzR7O679VhKkUKl1kd5rql+CJs3w4MPwlVXQVVVeJDN6ae3b3wiklt0p1CAVq4MRUjFxTBuXHjIzXPPKSGIiJJCh9eczmnvvgsXXhgqmidPhuHDwxhGc+fCgQe2V8QikstUfNSBpds57bnn4MYb4bHHwjDXX/86/M//hOcoi4jEy+idgpmNMrN3zWyBmV2ZYP0gM5tlZq+a2VwzOymT8eSbdDqnTZkS+hn85z9wzTWhj8Jvf6uEICKJZexOwcw6A3cCXwIqgZfMbIa7vxW32WRgmrv/2sz2B54AijMVU75J1Tnt9tvhu9+Fk04KLYv0uEsRSSWTdwojgAXuvtDdPwceBE5tsI0D20fvdwCWZjCevNNU57QbbwwJ4fTTYfp0JQQRSU8mk8IA4MO4+cpoWbxrgHPMrJJwl/CdRDsyswlmNsfM5lRVVWUi1g4pUee0bt3CYzK//30YPRoeekh9DkQkfZlMCpZgmTeYHwP8wd0HAicB95tZo5jcfYq7l7t7ef/+/TMQasfUsHPaoEFw3HGhv8G4cWEMoy5dsh2liHQkmUwKlcBucfMDaVw89E1gGoC7/xvoCvTLYEx5Z+zY8FS0rVvhjDPCENff+hb87nfQuXO2oxORjiaTSeElYC8zG2xm2wKjgRkNtlkCHAtgZvsRkoLKh5qppgYuughuvRUuuQR+/evQb0FEpLlSnjrMbKKZ9Wnujt29GpgIzATeJrQymmdm15rZKdFm3wPGm9nrwB+Bce7esIhJmlBTA+PHw29+A1deCbfcEoqSRERaIp0mqTsTmpO+AtwDzEz3xO3uTxAqkOOXXRX3/i3gsPTDlXjuoRPaPfeEIa9//GMlBBFpnZR3Cu4+GdgL+B0wDnjPzH5qZnp8e5b96EehL8L3vqeEICJtI62S5+jO4ONoqgb6AH82sxszGJs04Wc/C01Sx4+Hm25SQhCRtpGy+MjMvgucC6wE7gb+1923RE1H3wOuyGyI0tCvfhXqD8aMCZXKSggi0lbSqVPoB5zh7ovjF7p7jZmdnJmwJJmpU+Hii+ErX4F771WzUxFpW+kUHz0BrI7NmFkvMzsIwN3fzlRgEsQPjf2FL8C558Ixx8C0aeqYJiJtL52k8Gtgfdz8hmiZZFhsaOzFi0NLo9gIH1/7GnTtmt3YRCQ/pZMULL4JqrvXoOcwtItEQ2PX1MBPfpKdeEQk/6WTFBaa2XfNrEs0XQIszHRgknpobBGRtpZOUvg2cCjwEWE8o4OACZkMSoKmhsYWEcmEdDqvrXD30e7+BXffyd2/5u4r2iO4QnfenkWbAAAS70lEQVT66Y2Xde8e+ieIiGRCOv0UuhJGMx1CGLAOAHc/P4NxFbyqKnjggTAstjt8+GG4Q7j++vrPXxYRaUvpVBjfD7wDnABcC4wlDHAnGeIO3/42rF0LTz8NJSXZjkhECkU6dQp7uvuPgA3ufi/wZWBoZsMqbBUV8Ne/hlZGSggi0p7SSQpbote1ZlZCeJZyccYiKnCVlTBxIhx6aBjoTkSkPaVTfDQlep7CZMJDcnoCP8poVAXKHS64ALZs0RAWIpIdTSaFaNC7T919DTAb2L1doipQd90FM2fCnXfCnntmOxoRKURNFh9FvZcntlMsBe399+Hyy+G440Ils4hINqRTp/APM7vczHYzsx1jU8YjKyBbt8K4caG46J579HxlEcmedOoUYv0RLo5b5qgoqc3ceSc8/zz84Q+w227ZjkZEClnKpODug9sjkEL1q1+F5ywDXHUVbLONOqeJSPak06P5G4mWu/t9bR9OYamogO9+N7Q6gjDQ3YRoVCklBhHJhnRKr78YNx0OXAOcksGYCsbll4f6hHgbN4Yhs0VEsiGd4qPvxM+b2Q6EoS+kFWpq4OOPE6/T0Ngiki0taeeyEdirrQMpNBUVyddpaGwRyZZ06hQeJbQ2gpBE9gemZTKofPfpp3DFFbDHHrB0KWzaVLdOQ2OLSDal0yT153Hvq4HF7l6ZoXgKwnXXhaKj//wH3nsv1CEsWaKhsUUk+9JJCkuAZe7+GYCZdTOzYndflNHI8tS778Ktt8J558GIEWFSEhCRXJFOncKfgJq4+a3RMmkm99AnoVs3uOGGbEcjItJYOncK27j757EZd//czLbNYEx56/HH4ckn4eabYaedsh2NiEhj6dwpVJlZbb8EMzsVWJm5kPLT5s3hLmHffcPzEkREclE6dwrfBirM7I5ovhJI2MtZkrvlljAS6t//DtvqPktEclQ6ndfeBw42s56Aufu6zIeVXz7+OLQ4Ou00+NKXsh2NiEhyKYuPzOynZtbb3de7+zoz62Nm17VHcPni3nthwwb4v//LdiQiIk1Lp07hRHdfG5uJnsJ2Ujo7N7NRZvaumS0wsysTrL/FzF6LpvlmtjbRfjoyd7j/fjjkENhnn2xHIyLStHSSQmcz2y42Y2bdgO2a2D62XWfgTuBEQi/oMWa2f/w27n6puw939+HA7cBfmxN8R/DaazBvXuif0KkTFBc3PcSFiEg2pVPRPBV42sx+H82fB9ybxudGAAvcfSGAmT0InAq8lWT7McDVaey3Q4mNeLp6dXhdvFjDY4tI7kp5p+DuNwLXAfsRrvifBIrS2PcA4MO4+cpoWSNmVgQMBp5Jsn6Cmc0xszlVVVVpfHVuqK4OrY0a0vDYIpKr0h0l9WNCr+YzgWOBt9P4jCVY5gmWAYwG/uzuWxOtdPcp7l7u7uX9+/dPJ96c8PTTjZ+XEKPhsUUkFyUtPjKzvQkn6zHAKuAhQpPUo9PcdyUQ/8ThgcDSJNuOpv4zoPPC/feHeoSamsbrNDy2iOSipu4U3iHcFXzF3Ue6++2EcY/S9RKwl5kNjobFGA3MaLiRme0D9AH+3Yx957z162H6dDjyyDAcdjwNjy0iuaqppHAmodholpn91syOJXGRUELuXg1MBGYSipumufs8M7s2ftgMwp3Ig+6erGipQ5o+PdQdXHstTJkCRUVgFl6nTFEls4jkJkt1LjazHsBphJP3MYSWR9PdPUEVauaVl5f7nDlzsvHVzXL88bBgQRjawtJOpSIimWFmL7t7eart0ml9tMHdK9z9ZEK9wGtAo45oUmfp0lDJfM45Sggi0rE06xnN7r7a3e9y92MyFVA+eOCBULl8zjnZjkREpHmalRQkPfffH56otvfe2Y5ERKR5lBTa2Ny5Yfr617MdiYhI8ykptLGpU2GbbWD06GxHIiLSfEoKbWjr1jDY3YknQr9+2Y5GRKT5lBTaQEVFGP10m21Cy6Pi4mxHJCLSMkoKrVRREUY9Xby4btndd2t4bBHpmJQUWmnSpNBzOd6mTRoFVUQ6JiWFVko22qlGQRWRjkhJoZWSjXaqUVBFpCNSUmil66+H7Ro8nFSjoIpIR6Wk0EqjRkHPnqHlEWgUVBHp2NJ5RrMkUVMD3/gGrFsHL74IBx6Y7YhERFpHSaEVbroJnngC7rhDCUFE8oOKj1ro+edDs9OvfhUuuijb0YiItA0lhRaoqoKzz4bBg0NHNT0zQUTyhYqPmqmmJoyAumoVPP44bL99tiMSEWk7SgrNdMMNMHMm3HUXDB+e7WhERNqWio+aYdYsuOoq+NrXYPz4bEcjItL2lBTStHx5SAZ77x3uElSPICL5SMVHafjss1Cx/Mkn8I9/hM5qIiL5SEkhhepqGDMGnn02DIddUpLtiEREMkfFR02oqYFvfhMefhhuvz0UH4mI5DMlhSTc4dJL4b774NprYeLEbEckIpJ5SgpJ/PjHcNttITFMnpztaERE2oeSQgK33hqSwvnnw803q6WRiBQOJYUGfv/7cHdw5plhCGyzUMFcXAydOoVXPX9ZRPKVWh/F+etf4YIL4Pjjw4m/c+fwOmFC3XOYFy8O86BnJohI/tGdQmTWrND09OCDQ3KIPU1t0qS6hBCzcWNYLiKSb5QUIj/5Cey6Kzz2GPToUbd8yZLE2ydbLiLSkSkpAJ9/Dv/+N5x6KvTpU3/doEGJP5NsuYhIR6akALz8chjK4ogjGq+7/nro3r3+su7dw3IRkXyjpADMnh1eDz+88bqxY0MrpKKi0BKpqCjMq5JZRPJRRpOCmY0ys3fNbIGZXZlkm/9nZm+Z2TwzeyCT8SQzezbsuy/07594/dixsGhRGPZi0SIlBBHJXxlrkmpmnYE7gS8BlcBLZjbD3d+K22Yv4AfAYe6+xsy+kKl4ktm6NTxvefTo9v5mEZHck8k7hRHAAndf6O6fAw8CpzbYZjxwp7uvAXD3FRmMJ6G5c+HTTxPXJ4iIFJpMJoUBwIdx85XRsnh7A3ub2Qtm9qKZjUq0IzObYGZzzGxOVVVVmwYZq09QUhARyWxSSDRikDeY3wbYCzgKGAPcbWa9G33IfYq7l7t7ef9kBf8tNHt2GLpit93adLciIh1SJpNCJRB/qh0ILE2wzSPuvsXdPwDeJSSJduEOzz2nuwQRkZhMJoWXgL3MbLCZbQuMBmY02OZh4GgAM+tHKE5amMGY6nn3XaiqUlIQEYnJWFJw92pgIjATeBuY5u7zzOxaMzsl2mwmsMrM3gJmAf/r7qsyFVNDTfVPEBEpRBkdJdXdnwCeaLDsqrj3DlwWTe1u9mzYaSfYq90KrEREclvB9mh2h2efDUVHeoiOiEhQsElh8WKorFR9gohIvIJNCuqfICLSWEEnhd69oaQk25GIiOSOgk0Kzz0XWh11KtgjICLSWEGeEj/+GObPV9GRiEhDBZkUnnsuvKp/gohIfQWZFGbPDk9PKyvLdiQiIrmlYJPCoYdCly5hvqIiDIrXqVN4rajIZnQiItlTcElh9Wp44426+oSKCpgwIfRbcA+vEyYoMYhIYSq4pPDCC+HkH0sKkybBxo31t9m4MSwXESk0BZcUZs+GbbeFESPC/JIlibdLtlxEJJ8VXFJ47rmQELp1C/ODBiXeLtlyEZF8VlBJYf16ePnl+k1Rr78+tESK1717WC4iUmgKKim8+CJUV9fvtDZ2LEyZAkVFYbTUoqIwP3Zs9uIUEcmWjD5PIdfMnh2anR56aP3lY8cqCYiIQIHdKcyeDQccANtvn+1IRERyU8Ekhc2bQ/GRxjsSEUmuYJLCSy+FxKCkICKSXMEkhdhDdUaOzG4cIiK5rGAqms87LzxQp1+/bEciIpK7CuZOYZdd4JRTsh2FiEhuK5ikICIiqSkpiIhILSUFERGppaQgIiK1lBRERKSWkoKIiNRSUhARkVoFkRQqKqC4OIyQWlys5y+LiCST9z2aKypgwoS65zAvXhzmQcNli4g0lPd3CpMm1SWEmI0bw3IREakv75PCkiXNWy4iUsgymhTMbJSZvWtmC8zsygTrx5lZlZm9Fk0XtHUMgwY1b7mISCHLWFIws87AncCJwP7AGDPbP8GmD7n78Gi6u63juP566N69/rLu3cNyERGpL5N3CiOABe6+0N0/Bx4ETs3g9yU0dixMmQJFRWAWXqdMUSWziEgimWx9NAD4MG6+EjgowXZnmtkRwHzgUnf/sOEGZjYBmAAwqAXlPmPHKgmIiKQjk3cKlmCZN5h/FCh291LgKeDeRDty9ynuXu7u5f3792/jMEVEJCaTSaES2C1ufiCwNH4Dd1/l7puj2d8CB2YwHhERSSGTSeElYC8zG2xm2wKjgRnxG5jZLnGzpwBvZzAeERFJIWN1Cu5ebWYTgZlAZ+Aed59nZtcCc9x9BvBdMzsFqAZWA+MyFY+IiKRm7g2L+XNbeXm5z5kzJ9thiIh0KGb2sruXp9yuoyUFM6sCFidZ3Q9Y2Y7hNFcux6fYWkaxtYxia5nWxFbk7ilb6nS4pNAUM5uTTibMllyOT7G1jGJrGcXWMu0RW96PfSQiIulTUhARkVr5lhSmZDuAFHI5PsXWMoqtZRRby2Q8tryqUxARkdbJtzsFERFpBSUFERGplTdJIdUDfbLJzBaZ2RvRg4Sy2vPOzO4xsxVm9mbcsh3N7B9m9l702ieHYrvGzD6KexDTSVmKbTczm2Vmb5vZPDO7JFqe9WPXRGxZP3Zm1tXM/mtmr0ex/ThaPtjM/hMdt4eioXByJbY/mNkHccdteHvHFhdjZzN71cwei+Yzf9zcvcNPhGE03gd2B7YFXgf2z3ZccfEtAvplO44oliOAMuDNuGU3AldG768EfpZDsV0DXJ4Dx20XoCx634sw1Pv+uXDsmogt68eOMFpyz+h9F+A/wMHANGB0tPw3wIU5FNsfgLOy/W8uiusy4AHgsWg+48ctX+4UcuKBPh2Bu88mjDMV71Tqhi2/FzitXYOKJIktJ7j7Mnd/JXq/jjB44wBy4Ng1EVvWebA+mu0STQ4cA/w5Wp6t45YstpxgZgOBLwN3R/NGOxy3fEkKiR7okxP/KSIO/N3MXo4eGJRrdnL3ZRBOMMAXshxPQxPNbG5UvJSVoq14ZlYMHEC4ssypY9cgNsiBYxcVgbwGrAD+QbirX+vu1dEmWfv/2jA2d48dt+uj43aLmW2XjdiAW4ErgJpovi/tcNzyJSmk80CfbDrM3csIz6u+OHrSnKTn18AewHBgGXBzNoMxs57AX4D/cfdPsxlLQwliy4lj5+5b3X044ZkqI4D9Em3WvlFFX9ogNjMrAX4A7At8EdgR+H57x2VmJwMr3P3l+MUJNm3z45YvSSHlA32yyd2XRq8rgOmE/xi5ZHns2RbR64osx1PL3ZdH/3FrCA9iytqxM7MuhJNuhbv/NVqcE8cuUWy5dOyieNYC/ySU2/c2s9jQ/Vn//xoX26ioOM49PADs92TnuB0GnGJmiwjF4ccQ7hwyftzyJSmkfKBPtphZDzPrFXsPHA+82fSn2t0M4Nzo/bnAI1mMpR6r/yCm08nSsYvKc38HvO3uv4hblfVjlyy2XDh2ZtbfzHpH77sBxxHqPGYBZ0WbZeu4JYrtnbgkb4Qy+3Y/bu7+A3cf6O7FhPPZM+4+lvY4btmuXW+rCTiJ0OrifWBStuOJi2t3Qmuo14F52Y4N+COhKGEL4Q7rm4SyyqeB96LXHXMotvuBN4C5hBPwLlmKbSThVn0u8Fo0nZQLx66J2LJ+7IBS4NUohjeBq6LluwP/BRYAfwK2y6HYnomO25vAVKIWStmagKOoa32U8eOmYS5ERKRWvhQfiYhIG1BSEBGRWkoKIiJSS0lBRERqKSmIiEgtJQWRiJltjRsZ8zVrw9F2zaw4fvRXkVy1TepNRArGJg9DHogULN0piKRg4XkYP4vG3v+vme0ZLS8ys6ejgdOeNrNB0fKdzGx6NE7/62Z2aLSrzmb222js/r9HvWgxs++a2VvRfh7M0s8UAZQUROJ1a1B8dHbcuk/dfQRwB2EMGqL397l7KVAB3BYtvw141t2HEZ4PMS9avhdwp7sPAdYCZ0bLrwQOiPbz7Uz9OJF0qEezSMTM1rt7zwTLFwHHuPvCaOC5j929r5mtJAwdsSVavszd+5lZFTDQw4BqsX0UE4Zm3iua/z7Qxd2vM7MngfXAw8DDXjfGv0i7052CSHo8yftk2ySyOe79Vurq9L4M3AkcCLwcNwqmSLtTUhBJz9lxr/+O3v+LMIIlwFjg+ej908CFUPsQl+2T7dTMOgG7ufsswgNVegON7lZE2ouuSETqdIuewhXzpLvHmqVuZ2b/IVxIjYmWfRe4x8z+F6gCzouWXwJMMbNvEu4ILiSM/ppIZ2Cqme1AeIjKLR7G9hfJCtUpiKQQ1SmUu/vKbMcikmkqPhIRkVq6UxARkVq6UxARkVpKCiIiUktJQUREaikpiIhILSUFERGp9f8BMDkbgrUoQw8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that after ~20 epochs the accuracy on our validation set pretty much stagnates. As the accuracy on the training set is still increasing we have a high chance of overfitting to our training data. This is a wonderful example of why a validation set can be really helpful at times.\n",
    "\n",
    "Of course now we still would need to tackle this issue. This is beyond the scope of this little demonstration but one solution could be to do **early-stopping**. This means to simply evaluate the validation set accuracy over time and if it decreases (or only increases by very small numbers) we stop training as we won't get better. However there are also many other approaches to tackle overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final thoughts\n",
    "\n",
    "This tutorial was mostly taken from [the tensorflow tutorials site](https://www.tensorflow.org/tutorials/keras/basic_text_classification) so I want to give full credit to them. However I tried to explain some more details at certain steps to make it more clear if you are just getting started or maybe not so proficient on the basics of neural networks and the whole training procedure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
